### 1.Raw reads trimming (optional) using bbmap (for Nextera pair-end reads, trimming before demultiplexing): 

module load Java
bash /bbmap directory/bbduk.sh in1=inputfile.1.fq in2=inputfile.2.fq out1=filtered_reads.1.fq out2=filtered_reads.2.fq outm=failpairs.fq outs=pass_singleton.fq ref=nextera.fa 
	ktrim=r k=19 mink=11 hdist=1 stats=stats.txt mcf=0.5 maq=10 qtrim=rl trimq=10 minlen=100 tpe tbo

### Nextera.fa include a list of adapters and primers sequences,if you need, we have a separate file for this.Other parameters can be used as default if pair-end reads are 150 bp long. 
### Check BBDuk guide at https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbduk-guide/ to adjust parameters if needed. 


### 2.Nextera library demultiplexing: 

module load Java
bash /bbmap directory/demuxbyname2.sh in1= filtered_reads.1.fq in2=filtered_reads.2.fq out1=out1_%sample1R1.fq out2=out2_%sample1R2.fq prefixmode=f names=barcodes.txt

### To prepare barcode file, check how two barcodes (the i7 and i5) are provided in the sequence. The barcode file contains the list of barcode1+barcode2 and are provided in the sequence header. 
	##For instance, “i7 barcode+reverse-complementary of i5 barcode” could be a form of two barcodes in the header.  


### 3.Hisat2 index building and read alignment: 

/hisat2 directory/hisat2-build combine_reference.ref.fasta  combine_reference.ref   

### The Hisat2 index files will be generated for the combined reference (the reference generated through concatenation of the recipient and the donor plant genomes)) 

### Then,reads are aligned to the reference to obtain sam files from the demultiplexed (.fq) files  

for sample in `ls /Directory where demultiplexed samples are/*R1.fq`     ## run multiple .fq files at a time 
do
dir="/Directory where demultiplexed samples are"
base=$(basename $sample "_R1.fq")
/homes/hisat2 Directory/hisat2 -p 12 -x /hisat2 index files Directory/ combine_reference.ref -1 ${dir}/${base}_R1.fq -2 ${dir}/${base}_R2.fq -S ${base}.sam --no-spliced-alignment --no-unal &> ${base}.log  
done 

### should get single sam file and a log file per sample 


### 4.Selecting uniquely mapped concordant reads:

grep -v "^@" sample_name.sam | grep YT:Z:CP | grep NH:i:1 | cut -f 3,4 | sort -k1,1 -k2,2n | awk '{print $1 "\t" int($2 / 1000000) * 1000000}' | uniq -c >  sample_name.sam-1MBINS.txt  

### gives .txt file for each sample where first column will be raw read counts, second will be chromosome and the third column will be physical distance in the chromosomes as 
	## separated by 1 Mb bin. Bin size can be of your own choice. 


### 5.Read normalization:

readarray array < all-sample.txt   ## run array jobs in HPC, all-sample.txt includes the list of all .txt samples obtained in the previous step
name=$(echo ${array[$SLURM_ARRAY_TASK_ID]} | sed s'/.txt/_coverage.txt/')
awk -v SUM="$sum" 'BEGIN{OFS="\t"} {$5=($1/SUM)*10000000}{print}' ${array[$SLURM_ARRAY_TASK_ID]} > $name  ##normalized in 10 million reads per sample


### 6.Adding samples names into the output file:

for i in *txt
do
name=$(echo $i | sed 's/.sam-1MBINS_coverage.txt//')
awk -v NAME="$name" 'BEGIN{OFS="\t"}{$5=NAME} {print}' $i > ${i%1MBINS_*}namecolumn.txt
done


### 7.Filter output files to remove lines with the Unknown Chromosomes: 

for i in *txt
do
echo $i 
sed '/chrUn/d' $i > ${I%-namecolumn.txt*}KnownChronly.txt
done 


### 8.Cat samples and the chromosomes you like to plot and use ggplot2 in R to get read depth graph to confirm translocations:

